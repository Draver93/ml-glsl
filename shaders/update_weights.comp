#version 430
layout(local_size_x = 16, local_size_y = 16) in;

// Inputs: A = inputs[batch, input_size], Δ = deltas[batch, output_size] (row-major)
layout(std430) readonly buffer InputBuffer  { float inputs[]; };   // idx = b*input_size + i
layout(std430) readonly buffer DeltaBuffer  { float deltas[]; };   // idx = b*output_size + o

// Parameters and state
layout(std430)        buffer WeightBuffer { float weights[]; };    // idx = i*output_size + o
layout(std430)        buffer ADAM_MBuffer { float m[]; };
layout(std430)        buffer ADAM_VBuffer { float v[]; };

uniform int   input_size;
uniform int   output_size;
uniform int   batch_size;
uniform float learning_rate;
uniform float ADAM_beta1;
uniform float ADAM_beta2;
uniform int   use_batch_idx = -1;   // -1: full batch; >=0: select input column only
uniform float m_correction;         // 1 - beta1^(t+1) (precomputed on CPU)
uniform float v_correction;         // 1 - beta2^(t+1)

const float EPS = 1e-8;

shared float Asub[16][16];     // [i_tile, k_tile]
shared float Bsub[16][16];     // [k_tile, o_tile]

void main() {
  // Tile coordinates in (input, output) space
  uint iBase = gl_WorkGroupID.x * 16u;
  uint oBase = gl_WorkGroupID.y * 16u;

  uint iLocal = gl_LocalInvocationID.x;  // 0..15
  uint oLocal = gl_LocalInvocationID.y;  // 0..15

  uint iIdx = iBase + iLocal;
  uint oIdx = oBase + oLocal;

  if (iIdx >= uint(input_size) || oIdx >= uint(output_size)) return;

  float acc = 0.0;

  if (use_batch_idx >= 0) {
    // Single-sample update: pick input column from use_batch_idx,
    // but deltas come from batch row 0 (your projection net has batch_size==1).
    uint bIn    = uint(use_batch_idx);
    uint bDelta = 0u;

    float a = inputs[bIn    * uint(input_size)  + iIdx];
    float d = deltas[bDelta * uint(output_size) + oIdx];
    acc = a * d;   // effective batch = 1 → no averaging
  } else {
    // Tiled accumulation over batch K
    for (uint t = 0; t < (uint(batch_size) + 15u) / 16u; ++t) {
      uint k0 = t * 16u;

      // Load A^T tile: Asub[i_local, k_local] = inputs[(k0 + k_local), iIdx]
      uint kA = k0 + oLocal;
      Asub[iLocal][oLocal] =
          (kA < uint(batch_size)) ? inputs[kA * uint(input_size) + iIdx] : 0.0;

      // Load Δ tile: Bsub[k_local, o_local] = deltas[(k0 + k_local), oIdx]
      uint kB = k0 + iLocal;
      Bsub[iLocal][oLocal] =
          (kB < uint(batch_size)) ? deltas[kB * uint(output_size) + oIdx] : 0.0;

      barrier();

      // Multiply-accumulate over k_tile
      for (int k = 0; k < 16; ++k) {
        acc += Asub[iLocal][k] * Bsub[k][oLocal];
      }
      barrier();
    }
    // Mean over batch
    acc /= float(batch_size > 0 ? batch_size : 1);
  }

  // Fused Adam update (bias-corrected via precomputed corrections)
  uint wIdx = iIdx * uint(output_size) + oIdx;

  float gi = acc;
  float mi = m[wIdx] = ADAM_beta1 * m[wIdx] + (1.0 - ADAM_beta1) * gi;
  float vi = v[wIdx] = ADAM_beta2 * v[wIdx] + (1.0 - ADAM_beta2) * gi * gi;

  float mhat = (m_correction > 0.0) ? (mi / m_correction) : mi;
  float vhat = (v_correction > 0.0) ? (vi / v_correction) : vi;
  vhat = max(vhat, EPS);

  weights[wIdx] -= learning_rate * mhat / (sqrt(vhat) + EPS);
}