#version 430
layout(local_size_x = 16, local_size_y = 16) in;

layout(std430) readonly buffer AttentionWeights { float weights[]; }; // [num_heads * seq_len, seq_len]
layout(std430) readonly buffer BufferV { float V[]; };                // [model_dim, seq_len]
layout(std430) writeonly buffer BufferOutput { float buffer_output[]; };     // [model_dim, seq_len]

uniform int seq_len;
uniform int head_dim;
uniform int num_heads;

void main() {
    uint output_seq_pos = gl_GlobalInvocationID.x;  // output sequence position
    uint output_dim_idx = gl_GlobalInvocationID.y;  // output dimension index
    
    if (output_seq_pos >= uint(seq_len) || output_dim_idx >= uint(num_heads * head_dim)) return;
    
    // Decompose output dimension into head and head dimension
    uint head_idx = output_dim_idx / uint(head_dim);
    uint head_dim_idx = output_dim_idx % uint(head_dim);
    
    // Compute weighted sum: attention_weights @ V
    float result = 0.0;
    for (int key_pos = 0; key_pos < seq_len; key_pos++) {
        // Get attention weight for this head at [output_seq_pos, key_pos]
        uint attention_weight_idx = (head_idx * seq_len + output_seq_pos) * seq_len + key_pos;
        float attention_weight = weights[attention_weight_idx];
        
        // Get V value for this head at [key_pos, head_dim_idx]
        // Row-major indexing: [key_pos * model_dim + head * head_dim + head_dim_idx]
        uint v_row_major_idx = key_pos * (num_heads * head_dim) + head_idx * head_dim + head_dim_idx;
        float v_val = V[v_row_major_idx];
        
        result += attention_weight * v_val;
    }
    
    // Store result with row-major indexing: [output_seq_pos * model_dim + output_dim_idx]
    uint output_row_major_idx = output_seq_pos * (num_heads * head_dim) + output_dim_idx;
    buffer_output[output_row_major_idx] = result;
}