#include <chrono>
#include  <sstream>
#include <string>
#include <iomanip>
#include <iostream>
#include <fstream>
#include <cmath>
#include <cstdlib>
#include <ctime>
#include <array>
#include <vector>
#include <functional>
#include <algorithm>
#include <random>

#include <glm/glm.hpp>

#include "ActivationFunctions.h"
#include "AttentionBlock.h"
#include "Transformer.h"
#include "NeuralNetwork.h"
#include "MNISTLoader.h"
#include "BPE.h"
#include "Matrix.h"


#include <vector>
#include <cstdint>
#include <cmath>

uint32_t hash32(const std::string& str) {
    const uint32_t FNV_PRIME = 0x01000193; //   16777619
    const uint32_t OFFSET_BASIS = 0x811C9DC5; // 2166136261

    uint32_t hash = OFFSET_BASIS;
    for (char c : str) {
        hash ^= static_cast<uint8_t>(c);
        hash *= FNV_PRIME;
    }
    return hash;
}

std::vector<float> tokenToInputVector(const std::string& token) {
    uint32_t h = hash32(token);  // example: 0x9E3779B9
    std::vector<float> vec(32);
    for (int i = 0; i < 32; ++i) {
        vec[i] = ((h >> (i % 32)) & 1) ? 1.0f : 0.0f;  // crude binary split
    }
    return vec;
}

// Helper to read little-endian integers from file
template<typename T>
void readLE(std::ifstream& file, T& val) {
    file.read(reinterpret_cast<char*>(&val), sizeof(T));
    // On little-endian machines, no conversion needed
}

// Load BMP, convert to normalized grayscale float vector
std::vector<uint8_t> loadBMPtoGrayscale(const std::string& filename, int& outWidth, int& outHeight) {
    std::ifstream file(filename, std::ios::binary);
    if (!file) throw std::runtime_error("Failed to open BMP file");

    // --- Read BMP file header ---
    uint16_t bfType;
    readLE(file, bfType);
    if (bfType != 0x4D42) // 'BM' in little endian
        throw std::runtime_error("Not a BMP file");

    uint32_t bfSize, bfReserved, bfOffBits;
    readLE(file, bfSize);
    readLE(file, bfReserved);
    readLE(file, bfOffBits);

    // --- Read DIB header size ---
    uint32_t dibHeaderSize;
    readLE(file, dibHeaderSize);

    if (dibHeaderSize < 40 || dibHeaderSize > 128)
        std::cout << "Warning: Unexpected DIB header size: " << dibHeaderSize << std::endl;

    // Read the rest of the DIB header into buffer
    std::vector<uint8_t> dibHeader(dibHeaderSize);
    // We already read the first 4 bytes (dibHeaderSize), so copy that
    memcpy(dibHeader.data(), &dibHeaderSize, 4);
    // Read remaining bytes
    file.read(reinterpret_cast<char*>(dibHeader.data() + 4), dibHeaderSize - 4);

    // Extract width, height, planes, bitcount (from first 40 bytes)
    int32_t width = *reinterpret_cast<int32_t*>(&dibHeader[4]);
    int32_t height = *reinterpret_cast<int32_t*>(&dibHeader[8]);
    uint16_t planes = *reinterpret_cast<uint16_t*>(&dibHeader[12]);
    uint16_t bitCount = *reinterpret_cast<uint16_t*>(&dibHeader[14]);
    uint32_t compression = *reinterpret_cast<uint32_t*>(&dibHeader[16]);

    if (planes != 1) throw std::runtime_error("Unsupported BMP planes count");
    if (compression != 0) throw std::runtime_error("Compressed BMP not supported");

    // Only support 24-bit or 8-bit BMP here
    if (bitCount != 24 && bitCount != 8)
        throw std::runtime_error("Only 24-bit and 8-bit BMP supported");

    // Output dimensions
    outWidth = width;
    outHeight = (height > 0) ? height : -height; // Height can be negative to indicate top-down bitmap

    // --- Handle palette for 8-bit images ---
    std::vector<uint32_t> palette;
    if (bitCount == 8) {
        // Palette is after DIB header, each palette entry 4 bytes (B,G,R,0)
        size_t paletteSize = (bfOffBits - 14 - dibHeaderSize) / 4;
        palette.resize(paletteSize);
        for (size_t i = 0; i < paletteSize; ++i) {
            uint8_t b = file.get();
            uint8_t g = file.get();
            uint8_t r = file.get();
            uint8_t reserved = file.get();
            palette[i] = (r << 16) | (g << 8) | b;
        }
    }

    // --- Read pixel data ---
    file.seekg(bfOffBits, std::ios::beg);

    int rowSize = ((bitCount * width + 31) / 32) * 4; // row size is padded to 4 bytes
    std::vector<uint8_t> rowData(rowSize);

    std::vector<uint8_t> pixels(outWidth * outHeight);

    bool topDown = (height < 0);

    for (int row = 0; row < outHeight; ++row) {
        int readRow = topDown ? row : (outHeight - 1 - row);
        file.read(reinterpret_cast<char*>(rowData.data()), rowSize);

        for (int col = 0; col < outWidth; ++col) {
            if (bitCount == 24) {
                // 3 bytes per pixel: B G R
                int idx = col * 3;
                uint8_t b = rowData[idx];
                uint8_t g = rowData[idx + 1];
                uint8_t r = rowData[idx + 2];
                // Convert RGB to grayscale luminance (approx)
                float gray = (0.299f * r + 0.587f * g + 0.114f * b);
                pixels[readRow * outWidth + col] = gray;
            }
            else if (bitCount == 8) {
                uint8_t paletteIndex = rowData[col];
                uint32_t rgb = palette[paletteIndex];
                uint8_t r = (rgb >> 16) & 0xFF;
                uint8_t g = (rgb >> 8) & 0xFF;
                uint8_t b = rgb & 0xFF;
                float gray = (0.299f * r + 0.587f * g + 0.114f * b);
                pixels[readRow * outWidth + col] = gray;
            }
        }
    }

    return pixels;
}

// Helper: convert RGB to grayscale luminance
uint8_t rgbToGrayscale(uint8_t r, uint8_t g, uint8_t b) {
    // Use standard luminance formula
    return static_cast<uint8_t>(0.299f * r + 0.587f * g + 0.114f * b);
}

// Nearest neighbor resize for simplicity
std::vector<uint8_t> resizeImageNearestNeighbor(
    const std::vector<uint8_t>& srcPixels, int srcWidth, int srcHeight,
    int dstWidth, int dstHeight)
{
    std::vector<uint8_t> dstPixels(dstWidth * dstHeight);

    for (int y = 0; y < dstHeight; ++y) {
        int srcY = static_cast<int>(y * (float)srcHeight / dstHeight);
        for (int x = 0; x < dstWidth; ++x) {
            int srcX = static_cast<int>(x * (float)srcWidth / dstWidth);
            dstPixels[y * dstWidth + x] = srcPixels[srcY * srcWidth + srcX];
        }
    }

    return dstPixels;
}

// Convert RGB BMP image to MNIST format 28x28 grayscale pixels
std::vector<uint8_t> bmpToMNIST(
    const std::vector<uint8_t>& rgbPixels, int width, int height)
{
    // 1) Convert RGB to grayscale
    std::vector<uint8_t> grayscalePixels(width * height);
    for (int i = 0; i < width * height; ++i) {
        uint8_t r = rgbPixels[i * 3 + 0];
        uint8_t g = rgbPixels[i * 3 + 1];
        uint8_t b = rgbPixels[i * 3 + 2];
        grayscalePixels[i] = rgbToGrayscale(r, g, b);
    }

    // 2) Resize to 28x28
    std::vector<uint8_t> resizedPixels = resizeImageNearestNeighbor(
        grayscalePixels, width, height, 28, 28);

    // 3) Optionally invert colors if needed (MNIST digits are white-on-black)
    // If your BMP digit is black-on-white background, invert:
    // for (auto& px : resizedPixels) px = 255 - px;

    return resizedPixels; // 784 uint8 grayscale pixels
}


// Random float between -1 and 1
float random_norm_val() {
    return ((float)rand() / RAND_MAX) * 2 - 1;
}

void resetCursor() {
#ifdef _WIN32
    // Windows console API (best way)
    HANDLE hConsole = GetStdHandle(STD_OUTPUT_HANDLE);
    COORD coord = { 0, 0 };
    SetConsoleCursorPosition(hConsole, coord);
#else
    // ANSI escape sequence for UNIX-like systems
    std::cout << "\033[H"; // Move cursor to top-left
#endif
}

void print2DImage(const std::vector<uint8_t>& image, int width, int height) {
    const char* shades = " .:-=+*#%@"; // 10 levels of intensity

    for (int y = 0; y < height; ++y) {
        for (int x = 0; x < width; ++x) {
            float val = image[y * width + x] / (float)255;
            val = std::clamp(val, 0.0f, 1.0f); // safety clamp
            int shadeIdx = static_cast<int>(val * 9); // map [0,1] to 0-9
            std::cout << shades[shadeIdx];
        }
        std::cout << '\n';
    }
}

void digit_recognition() {
    // Network setup - simplified for testing
    const int inputSize = 784;
    const int hiddenSize = 64;
    const int outputSize = 10;

    const int batchSize = 8;
    const int steps = 2000000;

    NNGL::NeuralNetwork nn(batchSize);

    nn.addLayer(inputSize, hiddenSize, NNGL::ActivationFnType::SIGMOID);
    nn.addLayer(hiddenSize, hiddenSize, NNGL::ActivationFnType::RELU);
    nn.addLayer(hiddenSize, hiddenSize, NNGL::ActivationFnType::RELU);
    nn.addLayer(hiddenSize, hiddenSize, NNGL::ActivationFnType::TANH);
    nn.addLayer(hiddenSize, outputSize, NNGL::ActivationFnType::IDENTITY);

    std::vector<std::vector<uint8_t>> trainImages = NNGL::MNIST::loadImages("mnist/train-images.idx3-ubyte");
    std::vector<uint8_t> trainLabels = NNGL::MNIST::loadLabels("mnist/train-labels.idx1-ubyte");

    //print2DImage(trainImages[52], 28, 28);

    // Load test data
    std::vector<std::vector<uint8_t>> testImages = NNGL::MNIST::loadImages("mnist/t10k-images.idx3-ubyte");
    std::vector<uint8_t> testLabels = NNGL::MNIST::loadLabels("mnist/t10k-labels.idx1-ubyte");


    /*std::vector<std::vector<uint8_t>> testImages;
    std::vector<uint8_t> testLabels;
    int w, h;
    auto bmp = loadBMPtoGrayscale("test_case_1.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(1);
    bmp = loadBMPtoGrayscale("test_case_2.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(2);
    bmp = loadBMPtoGrayscale("test_case_3.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(3);
    bmp = loadBMPtoGrayscale("test_case_4.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(4);
    bmp = loadBMPtoGrayscale("test_case_5.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(5);
    bmp = loadBMPtoGrayscale("test_case_6.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(6);
    bmp = loadBMPtoGrayscale("test_case_7.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(7);
    bmp = loadBMPtoGrayscale("test_case_8.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(8);
    bmp = loadBMPtoGrayscale("test_case_9.bmp", w, h);
    testImages.push_back(bmp);
    testLabels.push_back(9);*/

    //print2DImage(testImages[0], 28, 28);

    // Track current position in dataset
    // Separate indices for train and test
    static size_t trainIndex = 0;
    static size_t testIndex = 0;

    const size_t totalTrainSamples = trainImages.size();
    const size_t totalTestSamples = testImages.size();

    nn.onTrainBatch([&](std::shared_ptr<NNGL::Matrix>& batchInputs, std::shared_ptr<NNGL::Matrix>& batchTargets, int batchSize) {
        batchTargets->clear();
        for (int column = 0; column < batchSize; column++) {
            // Use training data with wraparound
            size_t sampleIndex = (trainIndex + column) % totalTrainSamples;

            // Convert image from uint8_t to float and normalize (0-255 → 0-1)
            const auto& image = trainImages[sampleIndex];
            for (size_t pixel = 0; pixel < 784; ++pixel) 
                (*batchInputs)(pixel, column) = static_cast<float>(image[pixel]) / 255.0f;

            // Convert label to one-hot encoding
            uint8_t label = trainLabels[sampleIndex];
            (*batchTargets)(label, column) = 1.0f;
        }
        trainIndex = (trainIndex + batchSize) % totalTrainSamples;
    });

    nn.onTestBatch([&](std::shared_ptr<NNGL::Matrix>& batchInputs, std::shared_ptr<NNGL::Matrix>& batchTargets, int batchSize) {
        batchTargets->clear();
        for (int column = 0; column < batchSize; column++) {
            // Use training data with wraparound
            size_t sampleIndex = (testIndex + column) % totalTestSamples;

            // Convert image from uint8_t to float and normalize (0-255 → 0-1)
            const auto& image = testImages[sampleIndex];
            for (size_t pixel = 0; pixel < 784; ++pixel)
                (*batchInputs)(pixel, column) = static_cast<float>(image[pixel]) / 255.0f;

            // Convert label to one-hot encoding
            uint8_t label = testLabels[sampleIndex];
            (*batchTargets)(label, column) = 1.0f;
        }
        testIndex = (testIndex + batchSize) % totalTestSamples;
    });

    int stepsLeft = steps / batchSize;

    float initialLR = 0.0001f;
    float learningRate = initialLR;
    float decayRate = 0.98f;
    int decaySteps = steps / 1000; 

    while (stepsLeft > 0) {

        nn.train(learningRate);

        // Periodic GPU synchronization and cleanup
        if (stepsLeft % 100 == 0) {
            glFinish(); // Force GPU to complete all pending operations
            GLenum error = glGetError(); // Check for OpenGL errors
            if (error != GL_NO_ERROR) throw std::runtime_error("OpenGL Error detected: " + std::to_string(error) + " at training step " + std::to_string(steps / batchSize - stepsLeft));
        }

        // Status updates and weight display
        if (stepsLeft % (10000) == 0) {
            //resetCursor();
            //for (int i = 1; i < nn.m_Layers.size(); i++) nn.m_Layers[i]->printHeatmap();

            float accurracy = nn.eval(100);

            std::cout << "\nStep: " << (steps / batchSize - stepsLeft) * batchSize << " LR: " << learningRate << " Prediction: " << accurracy << "; " <<  std::endl;
        }

        // Learning rate decay
        learningRate = initialLR * std::pow(decayRate, ((steps / batchSize - stepsLeft) * batchSize) / (float)decaySteps);

        stepsLeft--;
    }

    std::cout << "\nTraining completed!" << std::endl;

    nn.run();
}

void sin_multiplication() {

    // Network setup - simplified for testing
    const int inputSize = 2;
    const int hiddenSize = 20;
    const int outputSize = 1;

    const int batchSize = 64;
    const int steps = 1000000; 

    NNGL::NeuralNetwork nn(batchSize);

    nn.onTrainBatch([&](std::shared_ptr<NNGL::Matrix>& batchInputs, std::shared_ptr<NNGL::Matrix>& batchTargets, int batchSize) {
        /*for (int i = 0; i < batchSize; i++) {
            float a = 3.14f * ((float)rand() / RAND_MAX) * 2.0f - 3.14f;
            float b_val = 3.14f * ((float)rand() / RAND_MAX) * 2.0f - 3.14f;

            batchInputs[i * 2 + 0] = a / 3.14f;
            batchInputs[i * 2 + 1] = b_val / 3.14f;
            batchTargets[i] = std::sin(a) * std::sin(b_val);
        } */   
    });
    nn.onTestBatch([&](std::shared_ptr<NNGL::Matrix>& batchInputs, std::shared_ptr<NNGL::Matrix>& batchTargets, int batchSize) {
        /*for (int i = 0; i < batchSize; i++) {
            float a = 3.14f * ((float)rand() / RAND_MAX) * 2.0f - 3.14f;
            float b_val = 3.14f * ((float)rand() / RAND_MAX) * 2.0f - 3.14f;

            batchInputs[i * 2 + 0] = a / 3.14f;
            batchInputs[i * 2 + 1] = b_val / 3.14f;
            batchTargets[i] = std::sin(a) * std::sin(b_val);
        }*/
    });

    nn.addLayer(inputSize, 1, NNGL::ActivationFnType::TANH);
    nn.addLayer(1, hiddenSize, NNGL::ActivationFnType::RELU);
    nn.addLayer(hiddenSize, hiddenSize, NNGL::ActivationFnType::LRELU);
    nn.addLayer(hiddenSize, hiddenSize, NNGL::ActivationFnType::SIGMOID);
    nn.addLayer(hiddenSize, hiddenSize, NNGL::ActivationFnType::TANH);
    nn.addLayer(hiddenSize, outputSize, NNGL::ActivationFnType::IDENTITY);

    float learningRate = 0.03f;
    int stepsLeft = steps / batchSize;

    while (stepsLeft > 0) {
        nn.train(learningRate);

        // Periodic GPU synchronization and cleanup
        if (stepsLeft % 100 == 0) {
            glFinish(); // Force GPU to complete all pending operations
            GLenum error = glGetError(); // Check for OpenGL errors
            if (error != GL_NO_ERROR) throw std::runtime_error("OpenGL Error detected: " + std::to_string(error) + " at training step " + std::to_string(steps / batchSize - stepsLeft));
        }

        // Status updates and weight display
        if (stepsLeft % (10000 / batchSize) == 0) {
            resetCursor();
            for (int i = 0; i < nn.m_Layers.size(); i++) {
                nn.m_Layers[i]->printHeatmap();
                std::cout << std::endl;
            }
            std::cout << "\nStep: " << (steps / batchSize - stepsLeft) * batchSize << " LR: " << learningRate << std::endl;
        }

        // Learning rate decay
        if (stepsLeft % 10000 == 0) learningRate *= 0.99f;

        stepsLeft--;
    }

    std::cout << "\nTraining completed!" << std::endl;

    nn.run();
}


void clean_word(std::string& word) {
    word.erase(std::remove_if(word.begin(), word.end(),
        [](unsigned char c) { return std::ispunct(c); }), word.end());
    std::transform(word.begin(), word.end(), word.begin(),
        [](unsigned char c) { return static_cast<char>(std::tolower(c)); });
}
void transformer() {
    //d_model	256–512
    //vocab_size	10000–20000
    //seq_len	64–256(max ~512)
    //batch size	1–4
    //# heads	4–8
    //layers	2–6

    int d_model = 128;  // Must be divisible by num_heads (8)
    int d_hidden = d_model * 4;
    int seq_len = 64;

    std::vector<std::string> filenames = { "english3.txt", "pg76287.txt", "english3.txt", "pg76287.txt", "english3.txt", "pg76287.txt","english3.txt", "pg76287.txt" };
    std::shared_ptr<NNGL::BPE> bytePairEnc = std::make_shared<NNGL::BPE>(1024 * 10);
    //bytePairEnc->trainFromFiles(filenames);
    //bytePairEnc->reduceVocab(50000);
    //bytePairEnc->save("bpe.checkpoint");
    bytePairEnc->load("bpe.checkpoint");
    std::string test = "the quick brown fox jumps over the lazy dog";


    std::vector<std::string> enc_tokens = bytePairEnc->tokenizeInput(test.c_str(), test.size());
    std::vector<std::string> dec_tokens = { "<SOS>" };

    std::shared_ptr<NNGL::Transformer> transformer = std::make_shared<NNGL::Transformer>( "bpe.checkpoint", d_model, d_hidden, seq_len );


    auto trainFromFile = [&](const std::string& filename) {
        std::ifstream infile(filename);
        if (!infile.is_open()) {
            std::cerr << "Error opening file: " << filename << std::endl;
            return;
        }

        std::string line;
        while (std::getline(infile, line)) {
            resetCursor();
            transformer->train(line);
        }

        infile.close();
    };
    trainFromFile("pg76287.txt");

    while (true) {
        std::string next_token = transformer->eval(test);

        test.append(next_token);
        // Stop condition (optional)
        if (next_token == "<EOS>") break;

        // Print/debug generated tokens
        std::cout << next_token << ' ';
    }
}

int main() {
    srand(time(nullptr));
    
    //new tokenizer
    // take a byte convert it in vector of 8 float where each float is bit 1.0f or 0.0f
    // feed it to ???
    /*NNGL::Trie trie;

    if (0) {
        trie.bulk_insert_from_file("english3.txt");
        trie.bulk_insert_from_file("pg76287.txt");
        //trie.prune_stddev_threshold(1.0); // Keep tokens >= (mean - 1×stddev)
        trie.save_tokens("tokens2.txt");
    }
    else trie.load_tokens("tokens2.txt");

    trie.prune_stddev_threshold(1.0);

    auto result2 = trie.tokenize("Hi my name is");
    std::vector<int> tokens;
    for (auto& it : result2) tokens.push_back(trie.get_token_id(it));*/
    
    // Initialize GLFW
    if (!glfwInit()) { std::cerr << "GLFW initialization failed!" << std::endl; return -1; }

    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 4);
    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);
    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);
    glfwWindowHint(GLFW_VISIBLE, GLFW_FALSE);

    GLFWwindow* window = glfwCreateWindow(1, 1, "NN Compute", nullptr, nullptr);
    if (!window) {
        std::cerr << "GLFW window creation failed!" << std::endl;
        glfwTerminate();
        return -1;
    }

    glfwMakeContextCurrent(window);
    if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) { std::cerr << "Failed to initialize GLAD!" << std::endl; return -1; }

    std::cout << "OpenGL Version: " << glGetString(GL_VERSION) << std::endl;
    transformer();
    //digit_recognition();

    std::cout << "Goodbye!" << std::endl;

    glfwDestroyWindow(window);
    glfwTerminate();

    return 0;
}